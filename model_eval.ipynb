{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import mne\n",
    "from eegatscale.models import LinearHeadBENDR\n",
    "from scripts.finetune_cv import H5PYDatasetLabeled\n",
    "from scripts.finetune_cv_nogroups import H5PYDatasetLabeled as H5PYDatasetLabeledNoGroups\n",
    "from torch.utils.data import DataLoader\n",
    "from eegatscale.transforms import StandardizeLabel, Standardize\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "# from dataset_utils import PickleDataset\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUSZ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912 samples in eval set\n"
     ]
    }
   ],
   "source": [
    "number = 2\n",
    "# tusz_model_dir = f\"/scratch/s194101/finetune_logs_all/tusz_noica_noica_60.0_nogroups_{number}/\"\n",
    "# tusz_model_dir = f\"/scratch/s194101/finetune_logs_all/tusz_noica_noica_60.0_nogroups_whole_dataset/\"\n",
    "\n",
    "# whole dataset split train\n",
    "tusz_model_dir = \"/scratch/s194101/finetune_logs_all/tusz_noica_noica_60.0_nogroups_whole_dataset_split_train\"\n",
    "\n",
    "models = glob(f\"{tusz_model_dir}/*/*/*.ckpt\")\n",
    "\n",
    "# we need to test all the models on the eval set\n",
    "data_dir_eval = \"/scratch/s194101/data/preprocessed_downstream/tusz/noica_60.0_titans_combine_eval_combined\"\n",
    "data_dir_train = \"/scratch/s194101/data/preprocessed_downstream/tusz/noica_60.0_titans_combine_whole_dataset_combined\"\n",
    "data_dir_split_train = \"/scratch/s194101/data/preprocessed_downstream/tusz/noica_60.0_titans_combine_whole_dataset_split_train_combined\"\n",
    "data_dir_split_eval = \"/scratch/s194101/data/preprocessed_downstream/tusz/noica_60.0_titans_combine_whole_dataset_split_eval_combined\"\n",
    "transform = StandardizeLabel()\n",
    "\n",
    "\n",
    "# data_eval = H5PYDatasetLabeledNoGroups(data_dir_eval, transform=transform)\n",
    "# data_eval = H5PYDatasetLabeledNoGroups(data_dir_train, transform=transform)\n",
    "# data_eval = H5PYDatasetLabeledNoGroups(data_dir_split_train, transform=transform)\n",
    "data_eval = H5PYDatasetLabeledNoGroups(data_dir_split_eval, transform=transform)\n",
    "print(f\"{len(data_eval)} samples in eval set\")\n",
    "\n",
    "\n",
    "\n",
    "dataloader_eval = DataLoader(data_eval, batch_size=80, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = next(iter(dataloader_eval))\n",
    "# print(x.shape, y.shape)\n",
    "\n",
    "# y_pred = model(x)\n",
    "\n",
    "# y_pred.argmax(dim=1), y\n",
    "\n",
    "# # y_pred.argmax(dim=1) == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model /scratch/s194101/finetune_logs_all/tusz_noica_noica_60.0_nogroups_whole_dataset_split_train/version_36/checkpoints/epoch=3-step=148.ckpt\n",
      "Initialized mask embedding and position encoder from  /scratch/s194101/finetune_logs_all/tusz_noica_noica_60.0_nogroups_whole_dataset_split_train/version_36/checkpoints/epoch=3-step=148.ckpt\n",
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_sem = 0\n",
    "best_model = None\n",
    "\n",
    "for model_path in tqdm(models):\n",
    "    print(f\"Testing model {model_path}\")\n",
    "    model = LinearHeadBENDR(model_path, encoder_h=512, in_features=19, out_features=2)\n",
    "    state_dict = torch.load(model_path, map_location=torch.device('cpu'))[\"state_dict\"]\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    print(\"model loaded\")\n",
    "\n",
    "\n",
    "    # test model on eval set\n",
    "    accs = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader_eval):\n",
    "            x, y = batch\n",
    "            y_pred = model(x)\n",
    "            batch_accuracy = (y_pred.argmax(dim=1) == y).float().mean().item()\n",
    "            accs.append(batch_accuracy)\n",
    "            # print(f\"Batch {i}, accuracy: {batch_accuracy}\")\n",
    "        \n",
    "        # standard error of the mean\n",
    "        accs = np.array(accs)\n",
    "        sem = np.std(accs) / np.sqrt(len(accs))\n",
    "\n",
    "\n",
    "        print(f\"Model {model_path} accuracy on eval set: {np.mean(accs)} +- {sem}\")\n",
    "        if np.mean(accs) > best_acc:\n",
    "            best_acc = np.mean(accs)\n",
    "            best_sem = sem\n",
    "            best_model = model_path\n",
    "        \n",
    "        print(f\"Best model so far: accuracy: {best_acc} +- {best_sem} | {best_model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on eval set:\n",
    "\n",
    "Best model so far: accuracy: 0.6795454545454546 +- 0.013922615366108731 | /scratch/s194101/finetune_logs_all/tusz_noica_noica_60.0_nogroups_4/version_9/checkpoints/epoch=14-step=150.ckpt\n",
    "\n",
    "Best model so far: accuracy: 0.768560604615645 +- 0.011691771714137506 | /scratch/s194101/finetune_logs_all/tusz_noica_noica_60.0_nogroups_whole_dataset/version_47/checkpoints/epoch=2-step=141.ckpt\n",
    "\n",
    "### on test set:\n",
    "\n",
    "Best model so far: accuracy: 0.979166673289405 +- 0.002758420816857501 | /scratch/s194101/finetune_logs_all/tusz_noica_noica_60.0_nogroups_whole_dataset/version_1/checkpoints/epoch=13-step=658.ckpt\n",
    "\n",
    "Best model so far: accuracy: 0.9757505257924398 +- 0.002019294366371989 | /scratch/s194101/finetune_logs_all/tusz_noica_noica_60.0_nogroups_whole_dataset_split_train/version_54/checkpoints/epoch=13-step=518.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMIDB data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
